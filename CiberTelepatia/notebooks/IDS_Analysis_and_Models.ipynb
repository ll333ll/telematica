{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS con Machine Learning (NSL-KDD) — EDA + 10 Modelos + 3 Ensambles\n",
    "\n",
    "Este notebook realiza un análisis exploratorio de datos (EDA) con Plotly y entrena múltiples modelos de Machine Learning para **detección de intrusiones** usando el dataset **NSL-KDD**. Incluye además tres métodos de ensamble (Voting, Stacking, Bagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "                            classification_report, confusion_matrix, roc_curve, precision_recall_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "                              AdaBoostClassifier, VotingClassifier, StackingClassifier, BaggingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "OUTPUTS = Path('CiberTelepatia') / 'outputs'\n",
    "OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_URL = 'https://raw.githubusercontent.com/jmnwong/NSL-KDD-Dataset/master/KDDTrain%2B.txt'\n",
    "TEST_URL = 'https://raw.githubusercontent.com/jmnwong/NSL-KDD-Dataset/master/KDDTest%2B.txt'\n",
    "\n",
    "COLUMN_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'difficulty'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_URL, header=None, names=COLUMN_NAMES)\n",
    "test_df = pd.read_csv(TEST_URL, header=None, names=COLUMN_NAMES)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    # Etiqueta binaria\n",
    "    train_df['is_attack'] = (train_df['attack'] != 'normal').astype(int)\n",
    "    test_df['is_attack'] = (test_df['attack'] != 'normal').astype(int)\n",
    "    # Quitar columnas no usadas\n",
    "    train_df.drop(columns=['attack', 'difficulty'], inplace=True)\n",
    "    test_df.drop(columns=['attack', 'difficulty'], inplace=True)\n",
    "    # One-hot categóricas\n",
    "    cat_cols = ['protocol_type', 'service', 'flag']\n",
    "    train_proc = pd.get_dummies(train_df, columns=cat_cols)\n",
    "    test_proc = pd.get_dummies(test_df, columns=cat_cols)\n",
    "    # Alinear columnas\n",
    "    missing = set(train_proc.columns) - set(test_proc.columns)\n",
    "    for c in missing: test_proc[c] = 0\n",
    "    extra = set(test_proc.columns) - set(train_proc.columns)\n",
    "    for c in extra: test_proc.drop(columns=[c], inplace=True)\n",
    "    test_proc = test_proc[train_proc.columns]\n",
    "    # Separar X,y\n",
    "    y_train = train_proc['is_attack']\n",
    "    X_train = train_proc.drop(columns=['is_attack'])\n",
    "    y_test = test_proc['is_attack']\n",
    "    X_test = test_proc.drop(columns=['is_attack'])\n",
    "    # Escalar numéricas (evitar dummies)\n",
    "    num_cols = [c for c in X_train.columns if not (c.startswith('protocol_type_') or c.startswith('service_') or c.startswith('flag_'))]\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "    return X_train, y_train, X_test, y_test, num_cols\n",
    "\n",
    "X_train, y_train, X_test, y_test, num_cols = preprocess(train_df, test_df)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA (Análisis Exploratorio) con Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Distribución de tipos de ataque (en train)\n",
    "attack_counts = train_df['attack'].value_counts().reset_index()\n",
    "attack_counts.columns = ['Attack Type', 'Count']\n",
    "fig = px.bar(attack_counts, x='Attack Type', y='Count', title='Distribución de Tipos de Ataque (Train)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'attack_type_distribution.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Balance de clases (normal vs ataque)\n",
    "class_counts = train_df.assign(is_attack = (train_df['attack'] != 'normal').astype(int))['is_attack'].value_counts()\n",
    "fig = px.pie(values=class_counts.values, names=['Normal', 'Ataque'], title='Balance de clases (Train)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'class_balance_pie.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Distribuciones numéricas (muestra)\n",
    "num_df = train_df.select_dtypes(include=np.number).copy()\n",
    "num_cols_simple = num_df.columns[:8]  # primeras 8 para ejemplo rápido\n",
    "fig = make_subplots(rows=2, cols=4, subplot_titles=list(num_cols_simple))\n",
    "r, c = 1, 1\n",
    "for col in num_cols_simple:\n",
    "    hist = go.Histogram(x=num_df[col], nbinsx=50, name=col, showlegend=False)\n",
    "    fig.add_trace(hist, row=r, col=c)\n",
    "    c += 1\n",
    "    if c==5:\n",
    "        r += 1; c = 1\n",
    "fig.update_layout(title='Distribuciones de variables numéricas (subset)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'numeric_distributions.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Boxplot de bytes totales (log) vs tipo de conexión\n",
    "tmp = train_df.copy()\n",
    "tmp['is_attack'] = (tmp['attack']!='normal').astype(int)\n",
    "tmp['importance_score'] = np.log(tmp['src_bytes'] + tmp['dst_bytes'] + 1)\n",
    "fig = px.box(tmp, x='is_attack', y='importance_score',\n",
    "             title='Puntuación de Importancia (log(src+dst+1)) por tipo', labels={'is_attack':'0=Normal,1=Ataque'})\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'importance_vs_attack.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Dispersión duración vs src_bytes (muestra), coloreado por ataque\n",
    "sample_df = train_df.sample(n=min(12000, len(train_df)), random_state=42)\n",
    "fig = px.scatter(sample_df, x='duration', y='src_bytes', color=(sample_df['attack']!='normal'),\n",
    "                 title='Duración vs src_bytes (muestra) por tipo', labels={'color':'Ataque?'},\n",
    "                 log_x=True, log_y=True)\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'duration_vs_src_bytes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importancia de variables (ExtraTrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "et.fit(X_train, y_train)\n",
    "imp = pd.Series(et.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(20)\n",
    "fig = px.bar(imp[::-1], orientation='h', title='Top 20 características por importancia (ExtraTrees)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'feature_importance_extratrees.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelado: 10+ clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogReg': LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1),\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'SVC_RBF': SVC(kernel='rbf', C=3.0, gamma='scale', probability=False),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=15),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    'GradBoost': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'LDA': LinearDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "def evaluate_all(models, X_train, y_train, X_test, y_test):\n",
    "    rows = []\n",
    "    for name, m in models.items():\n",
    "        print(f'Entrenando {name}…')\n",
    "        m.fit(X_train, y_train)\n",
    "        y_pred = m.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "        # ROC-AUC con decision_function o predict_proba si existe\n",
    "        try:\n",
    "            if hasattr(m, 'predict_proba'):\n",
    "                y_score = m.predict_proba(X_test)[:,1]\n",
    "            elif hasattr(m, 'decision_function'):\n",
    "                y_score = m.decision_function(X_test)\n",
    "            else:\n",
    "                y_score = None\n",
    "            roc = roc_auc_score(y_test, y_score) if y_score is not None else np.nan\n",
    "        except Exception:\n",
    "            roc = np.nan\n",
    "        rows.append({'model':name, 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'roc_auc':roc})\n",
    "    return pd.DataFrame(rows).sort_values(by=['f1','accuracy'], ascending=False)\n",
    "\n",
    "results = evaluate_all(models, X_train, y_train, X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Barras de Accuracy y F1\n",
    "fig = go.Figure()\n",
    "fig.add_bar(x=results['model'], y=results['accuracy'], name='Accuracy')\n",
    "fig.add_bar(x=results['model'], y=results['f1'], name='F1')\n",
    "fig.update_layout(barmode='group', title='Rendimiento por modelo (Accuracy y F1)', xaxis_title='Modelo', yaxis_title='Score')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'accuracy_f1_by_model.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Matrices de confusión de los 4 mejores por F1\n",
    "top4 = results['model'].head(4).tolist()\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=top4)\n",
    "r=c=1\n",
    "for name in top4:\n",
    "    m = models[name]\n",
    "    y_pred = m.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    heat = go.Heatmap(z=cm, x=['Pred Normal','Pred Ataque'], y=['Real Normal','Real Ataque'], showscale=False)\n",
    "    fig.add_trace(heat, row=r, col=c)\n",
    "    c += 1\n",
    "    if c==3: r += 1; c = 1\n",
    "fig.update_layout(title='Matrices de confusión (Top-4 F1)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'confusion_matrices_top4.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Curvas ROC de los 4 mejores (si es posible)\n",
    "fig = go.Figure()\n",
    "for name in top4:\n",
    "    m = models[name]\n",
    "    try:\n",
    "        if hasattr(m, 'predict_proba'):\n",
    "            y_score = m.predict_proba(X_test)[:,1]\n",
    "        elif hasattr(m, 'decision_function'):\n",
    "            y_score = m.decision_function(X_test)\n",
    "        else:\n",
    "            y_score = None\n",
    "        if y_score is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "            fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=name))\n",
    "    except Exception:\n",
    "        pass\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Azar', line=dict(dash='dash')))\n",
    "fig.update_layout(title='Curvas ROC (Top-4)')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'roc_curves_top4.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensambles: Voting, Stacking, Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting (hard)\n",
    "voting = VotingClassifier(estimators=[('lr', models['LogReg']), ('rf', models['RandomForest']), ('et', models['ExtraTrees'])], voting='hard', n_jobs=-1)\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred = voting.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "ens_results = pd.DataFrame([{'model':'Voting(hard)', 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'roc_auc':np.nan}])\n",
    "ens_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[('rf', RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)),\n",
    "               ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "               ('lda', LinearDiscriminantAnalysis())],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, solver='lbfgs'), n_jobs=-1)\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred = stacking.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "ens_results = pd.concat([ens_results, pd.DataFrame([{'model':'Stacking', 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'roc_auc':np.nan}])], ignore_index=True)\n",
    "ens_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42), n_estimators=100, random_state=42, n_jobs=-1)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "ens_results = pd.concat([ens_results, pd.DataFrame([{'model':'Bagging(Tree)', 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'roc_auc':np.nan}])], ignore_index=True)\n",
    "ens_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Comparativa final modelos + ensambles\n",
    "final_results = pd.concat([results, ens_results], ignore_index=True).sort_values(by=['f1','accuracy'], ascending=False)\n",
    "final_results.to_csv(OUTPUTS / 'results_summary.csv', index=False)\n",
    "fig = go.Figure()\n",
    "fig.add_bar(x=final_results['model'], y=final_results['f1'], name='F1')\n",
    "fig.update_layout(title='Comparativa final (Modelos + Ensambles) — F1', xaxis_title='Modelo', yaxis_title='F1')\n",
    "fig.show()\n",
    "fig.write_html(OUTPUTS / 'final_f1_comparison.html')\n",
    "final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

